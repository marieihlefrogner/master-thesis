\section{Summary}
We presented both a medical and technical background in chapter 2, in addition to mentioning related work to our thesis. We described both bipolar disorder and Montgomery-Ã…sberg Depression Rating Scale as part of the medical background. It was essential to gain knowledge about these topics because as students in Computer Science, our knowledge was limited. The technical background contains an introduction to ML, which is both theoretical and practical. In both the examples in this part and our model implementations, we used Keras, a ML framework in Python, because of its simplicity. 

In chapter 3, we described the dataset, our primary objectives and how we structured our data so that a CNN would be able to learn from it. The input data consisted of time-sliced segments mapped to the corresponding element in the output data. The output data contained one of three target values (from the demographics part of the dataset), which depended on the objective. We also touched upon different performance metrics that we used later in classification experiments.

In chapter 4, we introduced a regression test to see if we could learn something from any column in the demographics dataset. As we expected, only the MADRS score had a relation to whether a participant was in the control or condition group. Then we proceeded to implement our CNNs. We built three different models for our three primary objectives (the first two models were very similar, as only the number of output possibilities changed - depression level instead of control/condition). The last model was different in several layers, as it was built to predict MADRS values. 

We presented the training results in chapter 5. For each objective (including linear regression), we described the hyper-parameters we used when training the models. For the CNNs, we started out finding the optimal segment length for the input data before we trained the models. Then, we calculated performance scores for the trained models and did cross-validation to ensure the consistency of the models. For the classifiers, we also did a final experiment where we left participants out one by one and tested the models' capabilities to detect that particular participant.

We discussed our work in chapter 6 and came up with several issues that explain why our models performed the way they did. The number of participants is limited, which is the main issue that we think reduces the detection capabilities of the models when it comes to testing on completely untouched participants. Further improvements can be experimenting more with the segment lengths (input data) and other hyper-parameters. 

We compared our work to the research Garcia-Ceja, E. et al. performed on the same dataset (\cite{GarciaCeja2018_classification_bipolar}) and found that the difference between their decision tree and neural network and our CNN was not that significant as we thought it would be. We discussed real-world use cases for CNNs in mental health. The excellent performance from when we included data from all participants in training suggests that this kind of ML would perform better in detection within personal datasets.

\section{Contributions and Conclusions}

In this thesis, we have presented applied CNNs to the detection of depression, and our goal was to find whether CNNs as a type of ML applied on motor activity data is a valid approach to this. The dataset we applied ML to is called \textit{Depresjon} \cite{dataset}, and is a minute by minute log of motor activity for 23 depressed and 32 non-depressed participants. Furthermore, we divided our goal into three objectives, and we built a CNN for each of them.  

For the first objective, we created a CNN model that can classify with promising performance (F1-score of 0.70) whether a participant belongs to the condition group (bipolar and unipolar depressed patients) or the control group (healthy participants). 

Another CNN, for the second objective, detects one of three different levels of depression based on MADRS scores with the same data as input. We labeled participants in the control group as non-depressed and divided participants in the condition group into mildly depressed (MADRS between 7 and 19) and moderately depressed (MADRS between 20 and 34). Then we trained the model to detect this label for participants. We achieved an overall F1-score of 0.3 for this objective, which has a significant room for improvement. 

For the third objective, we built a prediction model that predicts the MADRS score of participants, again using the same motor activity dataset as input. We did not leave one participant out to test on as we did in the other objectives, as we did not have the computing power to train the model 55 times. Instead, we trained one model for 2700 epochs and achieved a mean squared error of approximately 4.0. 

We found that our models performed almost flawlessly (F1-scores above 0.99 for classification and mean squared error of approximately 4.0 for MADRS prediction) when training on data that included participants that we also tested on. There is a significant difference between these results and the \textit{leave one participant out} experiments. The difference indicates that CNNs can be more usefully applied to personal motor activity datasets, where the goal is, for example, to detect current mental states of bipolar patients. 

Usage of our depression detection system as it is today needs to happen together with experts in mental health. However, with the promising results supporting the first objective (F1-score of 0.70), we believe a better performing system with the same CNN can be developed if the dataset is optimized and collected further. 

\section{Future work}
First and foremost, leaving participants out of training one by one, as we did for the first two objectives, is something we want future researchers to also use as a performance evaluation. It is arguably the most accurate way of checking the consistency of a trained model. However, it may also be time-consuming depending on the complexity of the model and input data (as previously stated about our MADRS prediction model). In those cases, we suggest leaving multiple participants out instead of one (K-fold cross-validation on participants).

We did not find that CNNs were any better than decision trees on the kind of data that we provided to the models. Because the complexity of a CNN is higher, we want future researchers to make deeper CNN models and experiment with hyper-parameters. 

Researchers have experimented with different kinds of data in the field of mental health. Motor activity data \cite{obrien_depression, GarciaCeja2018_classification_bipolar}, Instagram images \cite{instagram_depression}, Twitter posts \cite{twitter_depression}, phone call logs \cite{faurholt_smartphone_bipolar, grunerbl_smartphone_bipolar}, text messages and voice data from microphones \cite{grunerbl_smartphone_bipolar} are examples of data used in earlier research. Diversity in the type of data is something we want to see in future research as well. We suggest including more participants, which we think would improve the performance significantly.

It can be useful to explore and compare different ML approaches with CNNs. Garcia-Ceja, E. et al. mentioned classification algorithms such as recurrent neural networks and hidden Markov models to be investigated in future research \cite{GarciaCeja2018_classification_bipolar}. We did not use these algorithms in this thesis, and therefore leave them as a suggestion to future researchers. 